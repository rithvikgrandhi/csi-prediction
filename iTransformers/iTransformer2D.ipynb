{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "# df=np.load(\"/Users/rohitviswam/Downloads/CSI-02-0005/H_32T4R_30_1RB.npy\")\n",
    "# data=df.reshape(2100,398,256)\n",
    "# data.shape\n",
    "# feature_len=data.shape[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50, 1000, 832)"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "import scipy.io\n",
    "# Load the .mat file\n",
    "file_path = '../EV_Rank_1_52_RBs_50_UEs_1000_snaps.mat'\n",
    "data = scipy.io.loadmat(file_path)\n",
    "\n",
    "# Extract the relevant data\n",
    "EV_data = data['EV_re_im_split']\n",
    "\n",
    "# Check the shape and structure of the extracted data\n",
    "data = EV_data\n",
    "del EV_data\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data = data[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50, 1000, 832)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from iTransformer import iTransformer\n",
    "from iTransformer import iTransformer2D\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_flattened = data.reshape(data.shape[0], -1)  # shape becomes (2100, 398*256)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data = data_flattened"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape: torch.Size([4950, 10, 832])\n",
      "Target shape: torch.Size([4950, 832])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_17607/93298084.py:30: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:275.)\n",
      "  inputs = torch.tensor(input_list, dtype=torch.float32)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "# Assuming `data` is already loaded and is of shape (2100, 398, 256)\n",
    "\n",
    "def preprocess_UE_data(data, lookback_len=10):\n",
    "    \"\"\"\n",
    "    Preprocesses data to create input-target pairs.\n",
    "    Args:\n",
    "        data: numpy array, (2100, 398, 256), original dataset\n",
    "        lookback_len: int, number of past timesteps to consider as input\n",
    "    \n",
    "    Returns:\n",
    "        inputs: torch Tensor, shape (samples, lookback_len, features)\n",
    "        targets: torch Tensor, shape (samples, features)\n",
    "    \"\"\"\n",
    "    num_UEs, num_timesteps, num_features = data.shape\n",
    "    input_list = []\n",
    "    target_list = []\n",
    "\n",
    "    for ue in range(num_UEs):\n",
    "        ue_data = data[ue]\n",
    "        for i in range(num_timesteps - lookback_len):\n",
    "            input_seq = ue_data[i: i + lookback_len]\n",
    "            target_seq = ue_data[i + lookback_len]\n",
    "            \n",
    "            input_list.append(input_seq)\n",
    "            target_list.append(target_seq)\n",
    "\n",
    "    inputs = torch.tensor(input_list, dtype=torch.float32)\n",
    "    targets = torch.tensor(target_list, dtype=torch.float32)\n",
    "\n",
    "    return inputs, targets\n",
    "\n",
    "# Usage example\n",
    "inputs, targets = preprocess_UE_data(data, lookback_len=10)\n",
    "\n",
    "print(\"Input shape:\", inputs.shape)   # Expected: (samples, 10, 256)\n",
    "print(\"Target shape:\", targets.shape) # Expected: (samples, 256)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Non-A100 GPU detected, using math or mem efficient attention if input tensor is on cuda\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from iTransformer import iTransformer\n",
    "\n",
    "# Set up parameters and data\n",
    "num_UEs, num_timesteps, num_features = data.shape\n",
    "lookback_len = 10\n",
    "forecast_len = 1\n",
    "\n",
    "\n",
    "# Define the iTransformer model\n",
    "model = iTransformer2D(\n",
    "    num_variates=num_features,\n",
    "    lookback_len=lookback_len,\n",
    "    dim=832,           # Model dimension\n",
    "    depth=6,           # Number of layers\n",
    "    heads=8,           # Number of attention heads\n",
    "    dim_head=64,       # Dimension per head\n",
    "    pred_length=forecast_len,  # Prediction horizon (1 in this case)\n",
    "    num_time_tokens=2,  # Single token per variate\n",
    "    use_reversible_instance_norm=True\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================================================================\n",
      "Layer (type:depth-idx)                             Output Shape              Param #\n",
      "====================================================================================================\n",
      "iTransformer2D                                     [4, 1, 832]               3,328\n",
      "├─RevIN: 1-1                                       [4, 832, 10]              1,664\n",
      "├─Sequential: 1-2                                  [4, 832, 6, 832]          --\n",
      "│    └─Rearrange: 2-1                              [3328, 1, 10]             --\n",
      "│    └─ConstantPad1d: 2-2                          [3328, 1, 15]             --\n",
      "│    └─Conv1d: 2-3                                 [3328, 832, 6]            9,152\n",
      "│    └─Rearrange: 2-4                              [4, 832, 6, 832]          --\n",
      "│    └─LayerNorm: 2-5                              [4, 832, 6, 832]          1,664\n",
      "├─Sequential: 1-3                                  [4, 832, 832]             --\n",
      "│    └─Linear: 2-6                                 [4, 832, 832]             9,152\n",
      "│    └─LayerNorm: 2-7                              [4, 832, 832]             1,664\n",
      "├─ModuleList: 1-4                                  --                        --\n",
      "│    └─ModuleList: 2-8                             --                        --\n",
      "│    │    └─SimpleGateLoopLayer: 3-1               [3344, 7, 832]            2,077,504\n",
      "│    │    └─TransformerBlock: 3-2                  [3344, 7, 832]            7,674,676\n",
      "│    │    └─TransformerBlock: 3-3                  [28, 836, 832]            7,674,644\n",
      "│    └─ModuleList: 2-9                             --                        --\n",
      "│    │    └─SimpleGateLoopLayer: 3-4               [3344, 7, 832]            2,077,504\n",
      "│    │    └─TransformerBlock: 3-5                  [3344, 7, 832]            7,674,676\n",
      "│    │    └─TransformerBlock: 3-6                  [28, 836, 832]            7,674,644\n",
      "│    └─ModuleList: 2-10                            --                        --\n",
      "│    │    └─SimpleGateLoopLayer: 3-7               [3344, 7, 832]            2,077,504\n",
      "│    │    └─TransformerBlock: 3-8                  [3344, 7, 832]            7,674,676\n",
      "│    │    └─TransformerBlock: 3-9                  [28, 836, 832]            7,674,644\n",
      "│    └─ModuleList: 2-11                            --                        --\n",
      "│    │    └─SimpleGateLoopLayer: 3-10              [3344, 7, 832]            2,077,504\n",
      "│    │    └─TransformerBlock: 3-11                 [3344, 7, 832]            7,674,676\n",
      "│    │    └─TransformerBlock: 3-12                 [28, 836, 832]            7,674,644\n",
      "│    └─ModuleList: 2-12                            --                        --\n",
      "│    │    └─SimpleGateLoopLayer: 3-13              [3344, 7, 832]            2,077,504\n",
      "│    │    └─TransformerBlock: 3-14                 [3344, 7, 832]            7,674,676\n",
      "│    │    └─TransformerBlock: 3-15                 [28, 836, 832]            7,674,644\n",
      "│    └─ModuleList: 2-13                            --                        --\n",
      "│    │    └─SimpleGateLoopLayer: 3-16              [3344, 7, 832]            2,077,504\n",
      "│    │    └─TransformerBlock: 3-17                 [3344, 7, 832]            7,674,676\n",
      "│    │    └─TransformerBlock: 3-18                 [28, 836, 832]            7,674,644\n",
      "├─ModuleList: 1-5                                  --                        --\n",
      "│    └─Sequential: 2-14                            [4, 1, 832]               --\n",
      "│    │    └─Linear: 3-19                           [4, 832, 1]               833\n",
      "│    │    └─Rearrange: 3-20                        [4, 1, 832]               --\n",
      "====================================================================================================\n",
      "Total params: 104,588,401\n",
      "Trainable params: 104,588,209\n",
      "Non-trainable params: 192\n",
      "Total mult-adds (Units.GIGABYTES): 197.12\n",
      "====================================================================================================\n",
      "Input size (MB): 0.13\n",
      "Forward/backward pass size (MB): 26098.91\n",
      "Params size (MB): 418.34\n",
      "Estimated Total Size (MB): 26517.38\n",
      "====================================================================================================\n"
     ]
    }
   ],
   "source": [
    "from torchinfo import summary\n",
    "\n",
    "# Assuming your model object is already defined as `model`\n",
    "\n",
    "# Generate a model summary (batch size and input dimensions as required)\n",
    "model_summary = summary(model, input_size=(4, 10, 832))  # Adjust batch size and input size accordingly\n",
    "\n",
    "# This will print a detailed summary with parameters, layers, and dimensions\n",
    "print(model_summary)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iTransformer2D(\n",
      "  (reversible_instance_norm): RevIN()\n",
      "  (layers): ModuleList(\n",
      "    (0-5): 6 x ModuleList(\n",
      "      (0): SimpleGateLoopLayer(\n",
      "        (norm): RMSNorm()\n",
      "        (to_qkva): Sequential(\n",
      "          (0): Linear(in_features=832, out_features=2496, bias=False)\n",
      "          (1): Rearrange('b n (qkva d) -> qkva (b d) n 1', qkva=3)\n",
      "        )\n",
      "        (maybe_post_ln): Identity()\n",
      "        (split_heads): Rearrange('(b d) n 1 -> b n d', d=832)\n",
      "      )\n",
      "      (1): TransformerBlock(\n",
      "        (rotary_emb): RotaryEmbedding()\n",
      "        (attn): Attention(\n",
      "          (rotary_emb): RotaryEmbedding()\n",
      "          (to_qkv): Sequential(\n",
      "            (0): Linear(in_features=832, out_features=1536, bias=False)\n",
      "            (1): Rearrange('b n (qkv h d) -> qkv b h n d', qkv=3, h=8)\n",
      "          )\n",
      "          (to_v_gates): Sequential(\n",
      "            (0): Linear(in_features=832, out_features=512, bias=False)\n",
      "            (1): SiLU()\n",
      "            (2): Rearrange('b n (h d) -> b h n d', h=8)\n",
      "          )\n",
      "          (attend): Attend(\n",
      "            (attn_dropout): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "          (to_out): Sequential(\n",
      "            (0): Rearrange('b h n d -> b n (h d)')\n",
      "            (1): Linear(in_features=512, out_features=832, bias=False)\n",
      "            (2): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (ff): Sequential(\n",
      "          (0): Linear(in_features=832, out_features=4436, bias=True)\n",
      "          (1): GEGLU()\n",
      "          (2): Dropout(p=0.0, inplace=False)\n",
      "          (3): Linear(in_features=2218, out_features=832, bias=True)\n",
      "        )\n",
      "        (attn_norm): LayerNorm((832,), eps=1e-05, elementwise_affine=True)\n",
      "        (ff_norm): LayerNorm((832,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "      (2): TransformerBlock(\n",
      "        (attn): Attention(\n",
      "          (to_qkv): Sequential(\n",
      "            (0): Linear(in_features=832, out_features=1536, bias=False)\n",
      "            (1): Rearrange('b n (qkv h d) -> qkv b h n d', qkv=3, h=8)\n",
      "          )\n",
      "          (to_v_gates): Sequential(\n",
      "            (0): Linear(in_features=832, out_features=512, bias=False)\n",
      "            (1): SiLU()\n",
      "            (2): Rearrange('b n (h d) -> b h n d', h=8)\n",
      "          )\n",
      "          (attend): Attend(\n",
      "            (attn_dropout): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "          (to_out): Sequential(\n",
      "            (0): Rearrange('b h n d -> b n (h d)')\n",
      "            (1): Linear(in_features=512, out_features=832, bias=False)\n",
      "            (2): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (ff): Sequential(\n",
      "          (0): Linear(in_features=832, out_features=4436, bias=True)\n",
      "          (1): GEGLU()\n",
      "          (2): Dropout(p=0.0, inplace=False)\n",
      "          (3): Linear(in_features=2218, out_features=832, bias=True)\n",
      "        )\n",
      "        (attn_norm): LayerNorm((832,), eps=1e-05, elementwise_affine=True)\n",
      "        (ff_norm): LayerNorm((832,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (to_variate_token): Sequential(\n",
      "    (0): Linear(in_features=10, out_features=832, bias=True)\n",
      "    (1): LayerNorm((832,), eps=1e-05, elementwise_affine=True)\n",
      "  )\n",
      "  (to_time_tokens): Sequential(\n",
      "    (0): Rearrange('b v n -> (b v) 1 n')\n",
      "    (1): ConstantPad1d(padding=(5, 0), value=0.0)\n",
      "    (2): Conv1d(1, 832, kernel_size=(10,), stride=(1,))\n",
      "    (3): Rearrange('(b v) d t -> b v t d', v=832)\n",
      "    (4): LayerNorm((832,), eps=1e-05, elementwise_affine=True)\n",
      "  )\n",
      "  (pred_heads): ModuleList(\n",
      "    (0): Sequential(\n",
      "      (0): Linear(in_features=832, out_features=1, bias=True)\n",
      "      (1): Rearrange('b v n -> b n v')\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# Print the architecture by directly printing the model object\n",
    "print(model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# Define training settings\n",
    "# device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device = torch.device(\"cuda\")\n",
    "\n",
    "model.to(device)\n",
    "\n",
    "inputs = inputs.to(device)\n",
    "targets = targets.to(device)\n",
    "\n",
    "# Loss function and optimizer\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Training Loop\n",
    "epochs = 10\n",
    "batch_size = 32\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    epoch_loss = 0.0\n",
    "    num_batches = int(len(inputs) / batch_size)\n",
    "    \n",
    "    for batch in range(num_batches):\n",
    "     batch_inputs = inputs[batch * batch_size:(batch + 1) * batch_size]\n",
    "     batch_targets = targets[batch * batch_size:(batch + 1) * batch_size]\n",
    "\n",
    "     optimizer.zero_grad()\n",
    "     preds = model(batch_inputs)[forecast_len].squeeze(1)  # Remove the singleton dimension\n",
    "     loss = criterion(preds, batch_targets)\n",
    "     loss.backward()\n",
    "     optimizer.step()\n",
    "     epoch_loss += loss.item()\n",
    "\n",
    "\n",
    "    print(f\"Epoch {epoch+1}/{epochs}, Loss: {epoch_loss / num_batches:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def tabulate_predictions(inputs, targets, model, forecast_len=1, batch_size=64):\n",
    "    \"\"\"\n",
    "    Tabulates actual vs. predicted results.\n",
    "    Args:\n",
    "        inputs: torch Tensor, input data used to predict\n",
    "        targets: torch Tensor, actual target values\n",
    "        model: trained PyTorch model for making predictions\n",
    "        forecast_len: int, how many timesteps to forecast\n",
    "        batch_size: int, batch size to use in prediction\n",
    "\n",
    "    Returns:\n",
    "        DataFrame containing actual and predicted results.\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    all_preds = []\n",
    "    all_targets = []\n",
    "\n",
    "    num_batches = int(len(inputs) / batch_size)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in range(num_batches):\n",
    "            batch_inputs = inputs[batch * batch_size:(batch + 1) * batch_size]\n",
    "            batch_targets = targets[batch * batch_size:(batch + 1) * batch_size]\n",
    "\n",
    "            # Predict using the model\n",
    "            preds = model(batch_inputs)[forecast_len].squeeze(1)\n",
    "            all_preds.extend(preds.cpu().numpy())\n",
    "            all_targets.extend(batch_targets.cpu().numpy())\n",
    "\n",
    "    # Create DataFrame for easier tabulation and analysis\n",
    "    df_results = pd.DataFrame({\n",
    "        'Actual': [list(target) for target in all_targets],\n",
    "        'Predicted': [list(pred) for pred in all_preds]\n",
    "    })\n",
    "\n",
    "    return df_results\n",
    "\n",
    "# Example Usage:\n",
    "results_df = tabulate_predictions(inputs, targets, model, forecast_len=1, batch_size=64)\n",
    "print(results_df.head())  # Print the first few rows to verify\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "def plot_predictions(inputs, targets, model, forecast_len=1, num_samples=10, batch_size=64):\n",
    "    \"\"\"\n",
    "    Plots a comparison between actual and predicted values.\n",
    "    Args:\n",
    "        inputs: torch Tensor, input data used to predict\n",
    "        targets: torch Tensor, actual target values\n",
    "        model: trained PyTorch model for making predictions\n",
    "        forecast_len: int, how many timesteps to forecast\n",
    "        num_samples: int, how many samples to plot\n",
    "        batch_size: int, batch size to use in prediction\n",
    "\n",
    "    Returns:\n",
    "        None. Displays the plots.\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    predictions = []\n",
    "    actuals = []\n",
    "\n",
    "    num_batches = min(int(len(inputs) / batch_size), num_samples)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in range(num_batches):\n",
    "            batch_inputs = inputs[batch * batch_size:(batch + 1) * batch_size]\n",
    "            batch_targets = targets[batch * batch_size:(batch + 1) * batch_size]\n",
    "\n",
    "            preds = model(batch_inputs)[forecast_len].squeeze(1)\n",
    "            predictions.extend(preds.cpu().numpy())\n",
    "            actuals.extend(batch_targets.cpu().numpy())\n",
    "\n",
    "    # Convert to numpy arrays for easy plotting\n",
    "    predictions = np.array(predictions)\n",
    "    actuals = np.array(actuals)\n",
    "\n",
    "    # Plot each sample\n",
    "    plt.figure(figsize=(15, 8))\n",
    "    for i in range(num_samples):\n",
    "        plt.subplot(num_samples // 2, 2, i + 1)\n",
    "        plt.plot(actuals[i], label='Actual')\n",
    "        plt.plot(predictions[i], label='Predicted')\n",
    "        plt.legend()\n",
    "        plt.xlabel('Feature Index')\n",
    "        plt.ylabel('Value')\n",
    "        plt.title(f'Sample {i + 1}')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Example usage:\n",
    "plot_predictions(inputs, targets, model, forecast_len=1, num_samples=2, batch_size=64)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
