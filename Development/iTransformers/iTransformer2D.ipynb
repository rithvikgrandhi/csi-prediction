{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "# df=np.load(\"/Users/rohitviswam/Downloads/CSI-02-0005/H_32T4R_30_1RB.npy\")\n",
    "# data=df.reshape(2100,398,256)\n",
    "# data.shape\n",
    "# feature_len=data.shape[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50, 1000, 832)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "import scipy.io\n",
    "# Load the .mat file\n",
    "file_path = '../../EV_Rank_1_52_RBs_50_UEs_1000_snaps.mat'\n",
    "data = scipy.io.loadmat(file_path)\n",
    "\n",
    "# Extract the relevant data\n",
    "EV_data = data['EV_re_im_split']\n",
    "\n",
    "# Check the shape and structure of the extracted data\n",
    "data = EV_data\n",
    "del EV_data\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data = data[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50, 1000, 832)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from iTransformer import iTransformer\n",
    "from iTransformer import iTransformer2D\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_flattened = data.reshape(data.shape[0], -1)  # shape becomes (2100, 398*256)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data = data_flattened"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "# Assuming `data` is already loaded and is of shape (2100, 398, 256)\n",
    "\n",
    "def preprocess_UE_data(data, lookback_len=10):\n",
    "    num_UEs, num_timesteps, num_features = data.shape\n",
    "    input_list = []\n",
    "    target_list = []\n",
    "\n",
    "    for ue in range(num_UEs):\n",
    "        ue_data = data[ue]\n",
    "        for i in range(num_timesteps - lookback_len):\n",
    "            input_seq = ue_data[i: i + lookback_len]\n",
    "            target_seq = ue_data[i + lookback_len]\n",
    "            \n",
    "            input_list.append(input_seq)\n",
    "            target_list.append(target_seq)\n",
    "\n",
    "    inputs = torch.tensor(input_list, dtype=torch.float32)\n",
    "    targets = torch.tensor(target_list, dtype=torch.float32)\n",
    "\n",
    "    return inputs, targets\n",
    "\n",
    "# Usage example\n",
    "inputs, targets = preprocess_UE_data(data, lookback_len=10)\n",
    "\n",
    "print(\"Input shape:\", inputs.shape)   # Expected: (samples, 10, 256)\n",
    "print(\"Target shape:\", targets.shape) # Expected: (samples, 256)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from iTransformer import iTransformer\n",
    "\n",
    "# Set up parameters and data\n",
    "num_UEs, num_timesteps, num_features = data.shape\n",
    "lookback_len = 10\n",
    "forecast_len = 1\n",
    "\n",
    "\n",
    "# Define the iTransformer model\n",
    "model = iTransformer2D(\n",
    "    num_variates=num_features,\n",
    "    lookback_len=lookback_len,\n",
    "    dim=832,           # Model dimension\n",
    "    depth=10,           # Number of layers\n",
    "    heads=16,           # Number of attention heads\n",
    "    dim_head=128,       # Dimension per head\n",
    "    pred_length=forecast_len,  # Prediction horizon (1 in this case)\n",
    "    num_time_tokens=2,  # Single token per variate\n",
    "    use_reversible_instance_norm=True\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchinfo import summary\n",
    "\n",
    "# Assuming your model object is already defined as `model`\n",
    "\n",
    "# Generate a model summary (batch size and input dimensions as required)\n",
    "model_summary = summary(model, input_size=(4, 10, 832))  # Adjust batch size and input size accordingly\n",
    "\n",
    "# This will print a detailed summary with parameters, layers, and dimensions\n",
    "print(model_summary)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the architecture by directly printing the model object\n",
    "print(model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define training settings\n",
    "# device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device = torch.device(\"cuda\")\n",
    "\n",
    "model.to(device)\n",
    "\n",
    "inputs = inputs.to(device)\n",
    "targets = targets.to(device)\n",
    "\n",
    "# Loss function and optimizer\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Training Loop\n",
    "epochs = 10\n",
    "batch_size = 32\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    epoch_loss = 0.0\n",
    "    num_batches = int(len(inputs) / batch_size)\n",
    "    \n",
    "    for batch in range(num_batches):\n",
    "     batch_inputs = inputs[batch * batch_size:(batch + 1) * batch_size]\n",
    "     batch_targets = targets[batch * batch_size:(batch + 1) * batch_size]\n",
    "\n",
    "     optimizer.zero_grad()\n",
    "     preds = model(batch_inputs)[forecast_len].squeeze(1)  # Remove the singleton dimension\n",
    "     loss = criterion(preds, batch_targets)\n",
    "     loss.backward()\n",
    "     optimizer.step()\n",
    "     epoch_loss += loss.item()\n",
    "\n",
    "\n",
    "    print(f\"Epoch {epoch+1}/{epochs}, Loss: {epoch_loss / num_batches:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def tabulate_predictions(inputs, targets, model, forecast_len=1, batch_size=64):\n",
    "    model.eval()\n",
    "    all_preds = []\n",
    "    all_targets = []\n",
    "\n",
    "    num_batches = int(len(inputs) / batch_size)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in range(num_batches):\n",
    "            batch_inputs = inputs[batch * batch_size:(batch + 1) * batch_size]\n",
    "            batch_targets = targets[batch * batch_size:(batch + 1) * batch_size]\n",
    "\n",
    "            # Predict using the model\n",
    "            preds = model(batch_inputs)[forecast_len].squeeze(1)\n",
    "            all_preds.extend(preds.cpu().numpy())\n",
    "            all_targets.extend(batch_targets.cpu().numpy())\n",
    "\n",
    "    # Create DataFrame for easier tabulation and analysis\n",
    "    df_results = pd.DataFrame({\n",
    "        'Actual': [list(target) for target in all_targets],\n",
    "        'Predicted': [list(pred) for pred in all_preds]\n",
    "    })\n",
    "\n",
    "    return df_results\n",
    "\n",
    "# Example Usage:\n",
    "results_df = tabulate_predictions(inputs, targets, model, forecast_len=1, batch_size=64)\n",
    "print(results_df.head())  # Print the first few rows to verify\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "def plot_predictions(inputs, targets, model, forecast_len=1, num_samples=10, batch_size=64):\n",
    "    model.eval()\n",
    "    predictions = []\n",
    "    actuals = []\n",
    "\n",
    "    num_batches = min(int(len(inputs) / batch_size), num_samples)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in range(num_batches):\n",
    "            batch_inputs = inputs[batch * batch_size:(batch + 1) * batch_size]\n",
    "            batch_targets = targets[batch * batch_size:(batch + 1) * batch_size]\n",
    "\n",
    "            preds = model(batch_inputs)[forecast_len].squeeze(1)\n",
    "            predictions.extend(preds.cpu().numpy())\n",
    "            actuals.extend(batch_targets.cpu().numpy())\n",
    "\n",
    "    predictions = np.array(predictions)\n",
    "    actuals = np.array(actuals)\n",
    "\n",
    "    # Plot each sample\n",
    "    plt.figure(figsize=(15, 8))\n",
    "    for i in range(num_samples):\n",
    "        plt.subplot(num_samples // 2, 2, i + 1)\n",
    "        plt.plot(actuals[i], label='Actual')\n",
    "        plt.plot(predictions[i], label='Predicted')\n",
    "        plt.legend()\n",
    "        plt.xlabel('Feature Index')\n",
    "        plt.ylabel('Value')\n",
    "        plt.title(f'Sample {i + 1}')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "plot_predictions(inputs, targets, model, forecast_len=1, num_samples=2, batch_size=64)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
